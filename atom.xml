<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[blooming bridges gradually graduating]]></title>
  <link href="http://bloomingbridges.github.com/Sammelsurium/atom.xml" rel="self"/>
  <link href="http://bloomingbridges.github.com/Sammelsurium/"/>
  <updated>2012-12-13T17:27:11+00:00</updated>
  <id>http://bloomingbridges.github.com/Sammelsurium/</id>
  <author>
    <name><![CDATA[Florian Brueckner]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Persistence of Memory]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/the-persistence-of-memory/"/>
    <updated>2012-12-03T19:33:00+00:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/the-persistence-of-memory</id>
    <content type="html"><![CDATA[<p>&#8220;We have the technology, so we might as well use it&#8221;, seems to have been the theme for our last <em>DAT301</em> micro project. Equipped with a kinect device, our group decided after long debate that we should try and recreate famous landscapes by 3D scanning household appliances and food. So here goes the first of a series: Salvador Dalí&#8217;s Surrealist painting &#8220;The Persistence of Memory&#8221;, or, &#8220;that one with the melting clocks&#8221;:</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/dali_final.png" alt="The Persistence of Memory" /></p>

<p>In my naivety I assumed that it would be fairly simple to mash the scanned meshes together and make some quick refinements. However, the level of detail on these was way higher than expected and the whole scene became  unmanageable rather early in the composition process. Texturing would therefore also have been a nightmare so I stopped after putting on materials.</p>

<p>I tried cleaning up and to eventually reduce the amount of detail using <em>Meshlab</em>, but it didn&#8217;t seem much use either as it kept crashing whenever one deletec vertices from the scene. So in the end a couple of objects like the tree and the ground are actually created via traditional modelling.</p>

<p>It&#8217;s been a fun experiment nevertheless and I believe we captured the essence of the landscape fairly well for a one-day project. Here&#8217;s the original one more time for your reference:</p>

<p><img src="http://3.bp.blogspot.com/_qsSkaXuuUE8/TT6hVjc-L9I/AAAAAAAAAD4/1JnIshd9pCw/s1600/the_persistence_of_memory_-_1931_salvador_dali.jpg" alt="Original" /></p>

<p>Originally my aim was to have the painting explorable in stereoscopic 3D, the time-constraints however made this impossible. Also I think I like the idea of simply re-creating artwork more ever since I stumbled upon this <a href="http://recodeproject.com">computer art conservation project</a>. Apart from being a &#8220;copy&#8221; in a wider sense, this project was more an exploration of the polygonal aesthetic, so a less detailed art style such as expressionism tends to lend itself better than let&#8217;s say a photorealistic image of <em>Times Square</em>. And of course similar things have been done <a href="http://www.thecreatorsproject.com/blog/when-indiana-jones-met-dali-classic-paintings-become-8-bit-game-mashups">before</a>.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/indy_persistence.png" alt="Indiana Jones and the Persistence of Memory" />
&copy; <em>thecreatorsproject</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Homebrew 3D scanning and motion capturing]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/homebrew-3d-scanning-and-motion-capturing/"/>
    <updated>2012-12-03T19:32:00+00:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/homebrew-3d-scanning-and-motion-capturing</id>
    <content type="html"><![CDATA[<p>Today Mister <em>Musaab Garghouti</em> from the local company <a href="http://www.real-visual.com">Real Visual</a> came into our <em>Real-time</em> session to show us some of the projects he&#8217;s been involved with and to let us have a play with some rather cumbersome-looking hardware.</p>

<!-- ![MoCap session](https://dl.dropbox.com/u/998319/DAT/mocap.jpg) -->


<p>Musaab&#8217;s focus has very much been on 3D scanning and printing, so he&#8217;s given us a brief rundown of the most commonly used practices used in the industry, then went on to demonstrate how a consumer device such as <em>Microsoft&#8217;s</em> <em>Kinect</em> can be misused for scanning real-world objects and organisms such as myself.</p>

<p>What makes this possible is the way the <em>Kinect</em> camera works: On top of the video stream it receives through the lens, an infrared sensor is constantly scanning the field of vision for depth information. Thus you&#8217;re able to &#8220;feel&#8221; the surfaces by taking the device and moving it slowly around the object. The sensor is able to pick up details right down to a centimeter&#8217;s resolution, which is more than enough for what it was originally built to do.</p>

<p>As you can imagine it doesn&#8217;t work very well on see-through or reflective materials in general. The software we used to interface with the device to see if we can get it to produce us some motion capture data seemed quite temperamental, but that&#8217;s porbably down to the hacking nature of the exercise. I know too well that this sort of work requires a lot of stamina as you do need to re-do things over and over again.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/kinectme.png" alt="Kinect me" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scaffolding]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/scaffolding/"/>
    <updated>2012-11-26T23:05:00+00:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/scaffolding</id>
    <content type="html"><![CDATA[<p>The following is an attempt come up with a rudimentary structure for my dissertation. At this point I am still not exactly sure what my argument is going to be as there is still a lot of research to be undertaken. Another growing concern is that analysing other designers&#8217; work with a scientific eye might not be considered academic enough. Judge for yourself and feel free to chip in for some direction.</p>

<h2>The Expressiveness of the Pixel (working title) - Dissertation structure draft</h2>

<h3>Introduction</h3>

<ul>
<li>I am going to talk about how to make games that reach out of the screen and stay in people&#8217;s heads. The games analysed in this dissertation are made by a single person, so the techniques uncovered can be used by (and apply to) big studios alike.</li>
</ul>


<h3>Chapter 1 - The moving image versus the Interactive experience</h3>

<ul>
<li>There&#8217;s a trend among games with a high-production value to borrow elements from cinema in order to make them more entertaining (e.g. Uncharted series), whereas indiependent developers have shown that you can make more &#8216;meaningful&#8217; games with limited resources and even lack of talent.</li>
</ul>


<h3>Chapter 2 - Less is More</h3>

<ul>
<li><p>I pick three exemplary titles, describe what they do and why the work so well based on scientific evidence from the field of psychology</p></li>
<li><p>Thirty Flights of Loving by Brendon Chung</p>

<ul>
<li>&#8220;Thirty Flights of Loving is about 15 minutes long, as minimalist in its visuals as it is in its storytelling, and drops you straight into a linear, first-person narrative about love, betrayal and grand heists. It progresses at breakneck pace, bombarding you with imagery and incidental detail that might fly straight over your head the first time through. It tells a story almost entirely without words, written or spoken; this is the videogame equivalent of punchy, avant-garde short fiction.&#8221;</li>
</ul>
</li>
<li><p>Don&#8217;t Look Back - Terry Cavanagh</p>

<ul>
<li>A platformer that relies on a three colour palette</li>
</ul>
</li>
<li><p>Thomas Was Alone by Mike Bithell VS. Alphaland by Jonas Kyratzes</p>

<ul>
<li>All characters are just blocks, the ultimate reduction</li>
</ul>
</li>
</ul>


<h3>Chapter 3 - Just the right Amount of Ambiguity</h3>

<ul>
<li>Critical discussion where I compare the effectiveness of the above mentioned to equivalent commercial ones (i.e. Super Crate Box vs. Left 4 Dead) in terms of visual story-telling</li>
<li>Debate whether an older generation is more likely to engage with &#8220;pixel art&#8221; due to nostalgia</li>
</ul>


<h3>Chapter 4 - The Attraction of the Unknown</h3>

<ul>
<li>Here I outline more ways of achieving similar sentiments (narrative, sound, co-op)</li>
<li>IN//CUBUS - Discussion of the techniques used in my Final Year project</li>
</ul>


<h3>Chapter 5 - Conclusion: Do try this at home</h3>

<ul>
<li>But be aware that the methods outlined do not guarantee success</li>
<li>We need more empathy in games</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A taste of Unity]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/a-taste-of-unity/"/>
    <updated>2012-11-13T22:50:00+00:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/a-taste-of-unity</id>
    <content type="html"><![CDATA[<p>In anticipation of the upcoming <em>DAT301</em> workshop in immersive 3D and the variety of use cases for other assignments  that keep forming in front on my inner eye I started looking into the popular Danish game engine by the name of <em>Unity3D</em>.</p>

<p>When you open up the application for the first time you&#8217;re greeted by a fairly complex demo project (in the case of version 3.5b, <em>Angry Bots</em>) nested within an array of hideous-looking grey panels. On top of those floats a window that claims to hold all the information one needs to get up and running. Granted, moving around in the 3D scene view works like a charm (using 3Ds Max-style hotkeys Q,W,E,R for navigating, translating, rotating and scaling) and is way more intuitive than other 3D packages that I had the displeasure to work with lately.</p>

<p>Then came shock number two: No coding tutorial? You&#8217;re not even going to tell me how to rotate a cube around itself? Panic-stricken I clicked around the interface looking for clues. It appeared as if the general workflow of a unity developer consisted solely of buying models from the <em>Asset Store</em> and placing them into a scene. This certainly wasn&#8217;t a very pleasing thought and I refused to accept it as true since I have watched the <a href="http://www.indiebuskers.net">indiebuskers</a> make games with <em>Unity</em>, spending most of their time in MonoDevelop or Visual Studio, there must be another way..</p>

<p>When I happened to fall ill over the weekend I spent a whole day just watching all the <em>Unity</em> video tutorials I could find on <em>YouTube</em> from the comfort of my bed. Filled to the brim with new knowledge I gave it another shot and made my model of a walrus head rotate on top of a particle system. Sweet!</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/mondrian.png" alt="Mondrian le Morse" /></p>

<p>Importing models including textures was surprisingly pain-free. My weapon of choice was C#, although I noticed that <em>Unity</em>&#8217;s implementation of <em>JavaScript</em> seems to be more closely related to the <em>ActionScript</em> standard due to the use of static typing, which I like. Long time <em>Flash</em> devs even reported a similarity in their workflow which I can see to an extent. The way it works is you import your assets and attach so called &#8220;behaviours&#8221; to them, little scripts that each contain their own Init and Update loop (yes, all function names a capitalised..). You can save your script-laden asset as a &#8220;prefab&#8221; (think <em>MovieClip</em>), which you can then drag into the scene or instantiate through another script.</p>

<p>What took some time to adjust to, however, was that everything is based on vectors (i.e. you can&#8217;t just move an object two units to the left, but have to provide a new vector for its position), but that&#8217;s only a small sacrifice compared to learning WebGL and doing everything without an instant representation. This is actually really nice, once you pressed the play button you can inspect all the elements in your scene and make adjustments. This makes debugging a breeze.</p>

<p>Now to try something more challenging. How about I try to use it with a wiimote? Nope, you need the Pro version for that. Kinect? Pro version required. Hmm.. Shadows? Pro version! Can I at least get the dark interface skin? Sorry, no. So I went and acquired a student licence from the official reseller for the upcoming and much appraised version 4, which luckily only turned out to be around £90 rather than the full price of £1500.</p>

<p>In the end I regained my faith in the software (albeit the fact that it wouldn&#8217;t let me open the new version due to popular demand) and you may expect a lot more 3D work from me in the near future (or at least until my licence runs out).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The democratisation of TV privileges]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/the-democratisation-of-tv-privileges/"/>
    <updated>2012-11-03T13:27:00+00:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/the-democratisation-of-tv-privileges</id>
    <content type="html"><![CDATA[<h3>Inception</h3>

<p>When we were asked to create a piece of media whose playback was somehow influenced by an <em>RSS</em> feed for our second mini project, the initial collective response was something along the lines of &#8220;Not again!&#8221;. To make matters worse, Dr. Lock provided us with a code example, which only needed two minor changes in order for the weakest of students to create something &#8220;acceptable&#8221;. Where&#8217;s the fun in that?</p>

<p>So I teamed up with <a href="https://twitter.com/imaginehonesty">Lizzie Seymour</a> as we shared the sentiment that feeds didn&#8217;t do the module name much justice. Still within the workshop it crystallised that we wanted to experiment with audience participation, to hand the control over to our spectators as in pieces like <a href="http://seb.ly/work/pixelphones/">PixelPhones</a> by Seb Lee-Delisle. For demonstration purposes we&#8217;d stitch together a series of cute kitten videos and make everyone in the room rub their phone screens in order to &#8220;upvote&#8221; their favourite clip.</p>

<p>We tried several JS libraries for picking up gestures in mobile browsers, but couldn&#8217;t find one that picked up more than one finger swipes on the <em>Android</em> default browser reliably. When Simon expressed his growing concern that we&#8217;d get too close to the upcoming assignment in taking the feed out of the equation, we came up with a slightly different scenario: We&#8217;d take the largest source of free video material on the internet available (<em>YouTube</em>), project it onto a wall and gave everyone in the room access to the same remote control. Thus, <em>The democratisation of TV privileges</em> was born.</p>

<h3>Development</h3>

<p>I feared that if we wanted to go down the <em>Processing</em> route I&#8217;d have to write a script that scraped <em>YouTube</em> for videos and downloaded them in advance. That would have been neither feasible nor very in lign with copyright law, so we decided to stick with web technologies for this one. Luckily <em>YouTube</em>&#8217;s recent update to the Player API allows you to control embedded videos via <em>JavaScript</em>. The original purpose of the <em>chromeless player</em> was to allow for customisation of the controls, little did they know it would make my life much much easier.</p>

<p>Lizzie went off to write the backend, which would generate <em>YouTube</em> playlist for search terms and provide them in human-readable XML. As for the interactive part, I used this project as an excuse to dig deeper into <a href="http://nodejs.org">NodeJS</a> and their implementation of the WebSocket API as I felt this was too big a thing not to have in your toolbelt these days (as our projects in other modules so splendidly demonstrated). I used <a href="http://nodejitsu.com">nodejitsu.com</a> for hosting and <a href="http://socket.io">socket.io</a> for the real-time voting system.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/dotp_test.png" alt="DOTP Layer Cake aesthetic" /></p>

<p>Due to a lucky coincidence during a debugging session I discovered that the latest version of <em>Chrome</em> was able to apply transparency to embedded <em>Flash</em> movies. This meant that I&#8217;d be able to play back all the channels at once, which would make for a more dream-like aesthetic and perhaps even increase the level of immersion.</p>

<h3>Reception &amp; Further development</h3>

<p>It worked out quite well in the end. At least for a two week project. Simon didn&#8217;t seem very impressed, but the crowd loved it.</p>

<p>In the version we presented it was already possible to create new channels on the fly by calling a function from the browser&#8217;s console. That as well as the remote design could do with some love in my opinion. Ideally you also wouldn&#8217;t have to restart the server every time you wanted to have a session, rather you&#8217;d create a theatre of your own using a unique id so you could invite people on the internet to join. Alas, I am fed up with <em>WebSockets</em> and I&#8217;ll gladly hand such tasks to all you enthusiastic tinkerers out there who want to learn and or simply point out what I&#8217;ve been doing wrong (I know for instance that the way I bundled socket.io with the app was completely off). You can find the repository on my <a href="https://github.com/bloomingbridges/YouMote">GitHub</a>.</p>

<p>To this day I am still not entirely sure whether the struggle with <em>Node</em> was actually worth it. Expecially the package management causes a LOT of confusion in combination with hosting services and writing server-side <em>JavaScript</em> - albeit its familiarity - still seems blatantly pointless.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/dotp_snap1.png" alt="DOTP Screenshot" /></p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/dotp_snap2.png" alt="DOTP Screenshot" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Re-visiting blender]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/re-visiting-blender/"/>
    <updated>2012-11-03T13:24:00+00:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/re-visiting-blender</id>
    <content type="html"><![CDATA[<p>There comes a point in a hacker slash designer&#8217;s career where one realises that they haven&#8217;t touched 3D in a while. For me that point was during placement at <em>Refunk</em>, when I was doing research on the emerging <em>WebGL</em> standard and tried creating my geometry in <em><a href="http://mrdoob.com">Ricardo Cabello</a></em>&#8217;s <em>three.js</em> in code, one vertex at a time.</p>

<p>Perhaps the most formative experience I had in relation to three-dimensional computer graphics was listening to <em>Marcin Ignac</em>&#8217;s talk at <em>FITC Amsterdam</em>. His approach of making his own tools using Mac OS X technologies and his <a href="http://marcinignac.com/projects/cindermedusae/">Cindermedusae</a> project in particular refueled my passion for the field and even taught me some valuable and transferable things about programmatic animation in general.</p>

<p>Now as it often is the case you find yourself very motivated to create something when leaving a conference like that, so for the remaining duration of my time away from uni I set myself the task of re-creating my <em>blooming bridges over withering waters visualisation</em> in mind-blowing 3D using WebGL.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/spaceworms.png" alt="WebGL version of bloomingbridges.co.uk prototype" /></p>

<p>What I didn&#8217;t consider was - that as with learning any craft - it would take up a considerate amount of my time and spare time is a luxury item. A piece of software was needed that would allow me to speed up the process of &#8220;building&#8221; objects for my scene.</p>

<p>The preferred choice of 3D package in the office was <em>Cinema4D</em>, but what I had in my mind did not require a professional high-end solution to execute, I was only after little visual feedback. Being in the Netherlands and having only read positive things about <em>blender</em>&#8217;s recent interface makeover and <em>Cycles</em> rendering engine I felt intrigued to give it another chance after I had dismissed it so passionately in my second year of uni.</p>

<p>It wasn&#8217;t the most glorious idea I&#8217;ve ever had, but I couldn&#8217;t imagine finding the stamina to tame the temperemental behemoth that is <em>Maya</em> some more and learning an entirely new piece of software felt counter-productive. What&#8217;s there to say about the new <em>blender</em> that doesn&#8217;t make me loose myself in a fit of rage. Once again it is exemplary for my love-hate-relationship with <em>open-source</em> software:</p>

<p>The new UI looks definitely more pleaasing to the eye and less broken, but fitted within an unreliable window layout and decorated with new secondary panels it&#8217;s not inherently more efficient to use. The old key mapping has been scrapped as well. Where you once triggered a contextual menu for adding primitives to your scene by tapping the space bar, you are now greeted with a useless little help window. Not enough that a great deal of <em>blender</em>&#8217;s functionality still isn&#8217;t exposed in the interface, the options available still don&#8217;t give you an indication as to what key they respond to.</p>

<p>I can see the value of customisation in productivity software, but for the love of God is it too much to ask for to agree on a standard that just works? Also, whoever thought that integrating trackpad gestures into the software without any consideration for the consequences (it renders the 3D view literally unusable without an external mouse or graphics tablet) might want to contemplate a change of career.</p>

<p>The new rendering engine on the other hand looks quite promising. <em>Cycles</em> is a node-based renderer with <em>global illumination</em> (objects emitting light etc.) at its core for more realistic-looking results. Once again, the sporadic documentation makes it more difficult to pick up if you don&#8217;t have a load of time on your hands to experiment.</p>

<p>In conclusion I can say that re-learning <em>blender</em> was a daunting task, yet considering the free options out there presents just one of the many challenges that I feel I just had to master (I&#8217;m still hoping to be able to add <em>OpenFrameworks</em>, Max/MSP and OpenGL to my toolchain one day).</p>

<p><img src="https://dl.dropbox.com/u/998319/lowpolyhearts.jpg" alt="Low-poly hearts inspired by Helena Coard" />
An artwork inspired by Plymouth-based Illustrator <a href="http://www.helena-coard.co.uk">Helena Coard</a></p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/lilyfinal.png" alt="bloomingbridges v6 logo" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Birds and XBees - The immediate future of Birdwire]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/birds-and-xbees-the-immediate-future-of-birdwire/"/>
    <updated>2012-10-22T19:36:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/birds-and-xbees-the-immediate-future-of-birdwire</id>
    <content type="html"><![CDATA[<p>I&#8217;m pleased to report that the <em>Birdwire</em> presentation went rather well. Lee caught enough interest to approach us after the session and ask us whether we&#8217;d like to put one out in the open. Of course we agreed to take the project further - if there was time - so we agreed to meet up the coming Monday so Lee could provide us with some more equipment needed to make the birdhouse self-sustainable and wireless.</p>

<p>Somehow we didn&#8217;t quite manage to meet up so the future of Birdwire is a little cloudy at the moment. In the meantime I got the chance to play with XBees for our <em>Everyware</em> project, so the initial learning curve would be marginal. Due to the planned XBee incorporation the upload of the code to GitHub has also been put on hold for the time being, for which I apologise.</p>

<p><strong>EDIT 08.12.2012</strong></p>

<p>It&#8217;s fair to assume that Lee&#8217;s initial interest has vanished by now as he still hasn&#8217;t found the time to respond to my emails. In addition to our growing disappointment we noticed that the once so promising piece of woodwork that Anish contributed to the project is now being used as a mere doorstopper, but it doesn&#8217;t end here.</p>

<p>As friends and the internet pointed out to us, there have been scarily similar developments in other corners of the world almost simultaneously: Latvian artist <em>Voldemars Dudums</em>&#8217;s <a href="http://designtaxi.com/news/354532/Real-Birds-Post-Tweets-On-Twitter">Hungry Birds</a> project for one and David Bowen&#8217;s <a href="http://dwbowen.com/fly_tweet.html">Fly Tweet</a> explore pretty much the same concept.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/fly_tweet.jpg" alt="fly tweet" /></p>

<p>Going through the amounts of <em>facebook likes</em> comparable projects have amassed doesn&#8217;t faze me one bit, although it begs the question whether our idea of presenting ideas to the outside world is fundamentally flawed (We usually assume that all work is done once we created a project website and pushed it onto a web server). While working in groups and according to briefs never gives you that feeling of authorship that makes being an artist so rewarding I draw satisfaction from knowing that I&#8217;ve finally started to think like one.</p>

<p>At the end of the day I can still pride myself for having incepted the animal twitter client with the least visible interface. No keyboards were harmed during the development of this project :></p>

<p>Finally, I have found the time to prepare the birdwire codebase for the general public and immortalised it with its own <a href="https://github.com/bloomingbridges/Birdwire">GitHub repository</a> (for licencing reasons it doesn&#8217;t contain the font I&#8217;ve used in the Processing sketch, <em>Avenir Light</em>). Feel free to improve on it, maybe together we can convert birdwatchers into birdreaders and inspire many more bird-related projects to come.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The ultimate Shakespearean]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/the-ultimate-shakespearean/"/>
    <updated>2012-10-21T19:58:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/the-ultimate-shakespearean</id>
    <content type="html"><![CDATA[<p>At the start of this year I rejoined the <em>Amateur Dramatics</em> society. When the new, more ambitious committee were asking us to submit our own plays for the upcoming christmas showcase, the following ran through my head:</p>

<p>Since I am not anywhere decent at writing I thought I could let my computer write a play more me generating phrases and characters at random. This thought was hugely influenced by my recent experiments with the <a href="http://www.rednoise.org/rita/">RiTa</a> library for Processing, which has made its way into <a href="http://benashman.co.uk/p/birdwire">Birdwire</a> app.</p>

<p>However, since this approach would likely result in complete nonsense, I&#8217;d like to suggest the more sensible <em>Dadaist</em> way: I&#8217;d collect a few public domain plays and have a script pick out phrases and stage instructions and assign them to a fixed amount of characters. Essentially collaging literature, or perhaps even recycling.</p>

<p>The resulting play probably wouldn&#8217;t make the cut, yet I&#8217;m really eager to see one version acted out professionally as this would present quite the challenge to any actor regardless their skill level. Maybe by the time Easter comes along I will have one ready.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/shakespeare.jpg" alt="Jane Boyer - The complete work of William Shakespeare" /></p>

<p><em><strong>The complete work of William Shakespeare</strong> - &copy; 2011 <a href="http://janeboyer.com">Jane Boyer</a></em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hold the Line]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/hold-the-line/"/>
    <updated>2012-10-15T01:01:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/hold-the-line</id>
    <content type="html"><![CDATA[<p>My former housemate Rafael used to present me with his latest acquisitions that ranged from retro gaming hardware to iPhone accessories on a weekly basis. The least useful one, a phone handset that plugs into the bi-directional headphone jack of an iPhone, re-entered my trail of thoughts recently as I was thinking about gallery spaces.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/Smoke.jpg" alt="iPhone handset accessory" /></p>

<p>It certainly holds a certain novelty to attach a phone to a phone, but when plugged into a computer for instance it becomes an interface rather than an unwieldy extension. With the help of a sound shield one could have an Arduino play holding or elevator music for eternity through the handset whenever it&#8217;s picked up. With the help of capacitive sensors one could measure the tolerance levels of gallery viewers and visualise them on a nearby wall in one way or other.</p>

<p>I am not taking this anywhere, this entry simply marks the beginning of a series of blog posts where I jot down the more shareworthy ideas that cross my mind.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Birdwire]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/birdwire/"/>
    <updated>2012-10-14T23:47:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/birdwire</id>
    <content type="html"><![CDATA[<p>Thanks to Ben and Phil we now got a nice little website featuring an informative short clip up <a href="http://www.benashman.co.uk/p/birdwire">http://www.benashman.co.uk/p/birdwire</a>. You can follow the latest and breaking chitter via <a href="http://www.twitter.com/birdwireapp">@birdwireapp</a>.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/birdwire_site.png" alt="birdwire website" /></p>

<p>Meanwhile I&#8217;ve been busy refactoring my code and adding a couple of features. For instance you can now flip a switch in the interface and the interpreter will match your input against a dictionary and try to make sense of it. This will make for a much more meaningful output.</p>

<p>Furthermore can the Arduino&#8217;s sensor thresholds and other options be set dynamically from within the Processing sketch.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/birdwire_sketch.png" alt="birdwire beta screenshot" /></p>

<p>There are still a couple of edge cases and minor bugs that need my attention, but it will do for the presentation tomorrow. Once I&#8217;m happy I shall release the code to the general public. So if you&#8217;re keen on trying it out for yourself, you can either come along tomorrow, or simply keep an eye on my <a href="http://www.github.com/bloomingbridges">GitHub</a> ;)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Anxiety in Manhattan]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/anxiety-in-manhattan/"/>
    <updated>2012-10-09T01:48:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/anxiety-in-manhattan</id>
    <content type="html"><![CDATA[<p>Following up on the idea from last week&#8217;s session of making a game that will let people experience <em>Generalized Anxiety Disorder</em> first-hand, it is now at the time to talk details, visual style in particular.</p>

<p>Simply put, the objective is to walk from the one side of the screen to the other, like in many many other games before. Thankfully, our idea requires just a single platform and only minor modifications to the game engine ;) Now here&#8217;s the catch: Your avatar will die horrible deaths along the way (being stomped by <em>Godzilla</em>, struck by lightning, hit by a bus) at seemingly random moments. This will -  hopefully - make the player (i.e. you) hesitate to progress in the game, thus creating anxiety of the simple task that is crossing the street. Eventually you pass the crossing without any problems whatsoever and only then will you notice that all previous attempts of doing so took place in the character&#8217;s imagination only. The final screen will show some information on the disorder in order - pardon - to raise awareness.</p>

<p>Watson seemed pretty keen to try making some 8-bit retro graphics for the game, which is fine by me as no graphic style seems either more or less suitable for this kind of &#8220;game&#8221;. In order to put the player in a familiar (at least iconic), peaceful and realistic environment I suggested to model the screen after a crossing in New York City. Here&#8217;s moodboard for the setting that I have in mind:</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/anxiety_moodboard1.jpg" alt="Setting moodboard" /></p>

<p>And another one that depicts a variety of retro styles that we might end up with:</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/anxiety_moodboard2.jpg" alt="Visual style moodboard" /></p>

<p>Finally, a snapshot of our progress for the dev diary:</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/anxiety_preview.png" alt="Visual style moodboard" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Game Design 101]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/game-design-101/"/>
    <updated>2012-10-08T01:23:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/game-design-101</id>
    <content type="html"><![CDATA[<p>Tough luck. As students in the year prior complained about having to do too much programming for this module, this time around there will be next to none (at least for the first couple of weeks). Instead of relying on existing Flash skills to create a portfolio-extending piece of interactive art that can be put up on the internet and enjoyed by many, we will be working with Simon&#8217;s JavaScript-based (and rather limited) <a href="https://github.com/DAT303/PUP-Game-Engine">PUP Game Engine</a> for the time being.</p>

<p>And it doesn&#8217;t end here, we also get to do ALL THE THINGS that I spent most of my free time doing anyway: thinking up ideas for games. Heck, I even do it in the shower..
So anyway, let&#8217;s approach this with an open mind and play the game, if you pardon my pun.
We employed a variety of techniques to come up with ideas for a small game, looking at random wikipedia articles being one of them.</p>

<p>Our group stumbled upon the following:</p>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Varicella_(video_game)">Varicella</a> (a text-adventure set in Venice during the Renaissance)</li>
<li>South-East Asia</li>
<li><a href="http://en.wikipedia.org/wiki/Generalized_anxiety_disorder">Generalized anxiety disorder</a> (a disorder akin to severe paranoia)</li>
</ul>


<p>And those combined into the worst possible idea for a game imaginable resulted in:</p>

<blockquote><p>&#8220;An Italian piece of interactive fiction where you have to go into the city of Venice so you can witness your daughter giving birth to her child. Unfortunately you suffer from Alzheimer&#8217;s disease, so throughout the game you forget about commands, items you collected, your whereabouts or even how to spell.&#8221;</p></blockquote>

<p>The one-legged hamster that has to prevent the JFK assassination from happening was another one of my favourites. All jokes aside, I think we&#8217;ll be sticking to our original idea, which I happen to talk about in more detail in another blog post.</p>

<p>As a final thought experiment we&#8217;ve been asked to try and combine our two favourite games and think of how something like that could actually made possible. In my case that would be <em>Thirty Flights of Loving</em> and <em>Wipeout</em>, a narrative-heavy racing game in which you hardly ever get to control a vehicle. Oh and of course jumpcuts! :D</p>

<p>Later on I came across this gem by accident, hidden deep within the depths of the University library: <em>How to make Things with Videogames</em> by Ian Bogost. So far I can only recommend it.</p>

<p><img src="http://www.creativeapplications.net/wp-content/uploads/2012/01/bogost-videogames-cover-640x480.jpg" alt="book cover" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A twitter client for birds]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/a-twitter-client-for-birds/"/>
    <updated>2012-10-07T03:22:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/a-twitter-client-for-birds</id>
    <content type="html"><![CDATA[<p><img src="https://dl.dropbox.com/u/998319/DAT/birdhouse_infrographic.jpg" alt="birdhouse design" /></p>

<p>So how does one go about creating an interface for a twitchy little animal? We figured all it needs is a familiar environment (a birdhouse), a handful of seeds and a tiny microphone. Thanks to Anish&#8217;s connections we got the housing covered, the sound sensor we borrowed from the <em>i-DAT</em> office. The birdhouse turned out a little bigger than expected. Field tests will show whether we have to find another &#8220;target audience&#8221;;</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/birdwire_development.jpg" alt="birdwire development" /></p>

<p>A first dirty implementation of a Morse code interpreter in Processing revealed a fundamental problem with the approach. A quick recap. In Morse, the characters are distinguished by a unique sequence of dots (DIT) and dashes (DAHs, three times the length of a DIT). To signal the end of a character you pause for the length of three DITs or one DAH, significantly longer for a word break. This all requires timing, which the birds don&#8217;t necessarily care for, so the pause length needs to be variable.</p>

<p>In version #1 every sound above a certain threshold would generate a DIT. I would start listening for periods of pauses until I picked up a new peck. After a certain amount of inactivity I will insert a space character. As some characters end on DITs and others on DITs plus two pauses I will never be able to tell what the last character of the word was, this way the birdies only ever get to choose from half of the letters available.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/birdwire_screenshot.png" alt="birdwire v.0.1 screenshot" /></p>

<p>I propose another algorithm that requires two different inputs, they may even come from the same sensor just using slightly different thresholds. It also wouldn&#8217;t hurt to ensure that at least one character is detected for every input session. If the bird flies off before the tweet is finished, should it be sent out anyway? Should incoming data be collected, averaged and thresholds dynamically adjusted according to different species of birds? To answer these questions we need to test it out in the open, which isn&#8217;t exactly feasible for next week. Unless someone&#8217;s got a 20m long USB extension cable that is?</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/birdwire_puppet.jpg" alt="birdwire finger puppet" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Thoughts on NFC]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/thoughts-on-nfc/"/>
    <updated>2012-10-04T08:50:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/thoughts-on-nfc</id>
    <content type="html"><![CDATA[<p>Last night I witnessed the power of Near Field Communication, short <em>NFC</em>, with my own eyes when James transferred a web address from his <em>Google Nexus</em> phone to his <em>Nexus 7</em> tablet by rubbing the devices&#8217; backs against each other. While it may not yet be the most efficient and or natural way to pay for your latte in a coffee shop, I see opportunities for supermarkets, restaurants and hard to navigate spaces like malls or Portland Square to provide people with an easy way of accessing information like maps or daily specials.</p>

<p>The advantages over quick response codes are immediately evident: No more black and white stickers that we&#8217;ve all grown so very tired of and dynamic information on the spot that requires no connection to the internet (Think advent calendars!). The amount of data that can be transferred is limited of course, but technical limitations shouldn&#8217;t limit your imagination. Just imagine walking into a space that greets you with a physical map. One swipe with your phone and you have said map on your screen to take with you. Beautiful.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/nfc.jpg" alt="NFC teaser from gizmodo" /></p>

<p><strong>EDIT 09.10.2012</strong></p>

<p>As <em>Lee Nutbean</em> pointed out in today&#8217;s session, <em>NFC</em> tags can be re-written via freely available phone software if unprotected. A person concerned with their precious privacy may note that this technology would enable a hacker to retrieve and change the information stored on their passport. The activist would see an opportunity to disrupt marketing channels and create awareness for their campaign in a way that could best be described as &#8216;virtual vandalism&#8217;.</p>

<p>Me being on neither side I just want to play with the technology, alas it might take years for <em>NFC</em> to become commonplace if at all (<em>Apple</em> for one doesn&#8217;t seem to believe in it).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Inspiration: INSERT DISC]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/inspiration-insert-disc/"/>
    <updated>2012-10-04T08:50:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/inspiration-insert-disc</id>
    <content type="html"><![CDATA[<p>Looks like I&#8217;m having a bit of a lucky streak this week as I keep stumbling upon scarily relevant resources on the internet. Of course I will be sharing them with you lot.</p>

<p>Next up: This <em>rhizome</em> article, <a href="http://rhizome.org/editorial/2012/oct/2/insert-disc-digital-flaneurs-guide/">INSERT Disc: A digital flaneur&#8217;s guide</a>, which presents us with a novel way of embedding data into buildings, thus relating beautifully to our exploration of ubiquitous computing in the <em>Everyware</em> (DAT302) module.</p>

<p>The gist is that the <a href="http://www.movingimage.us">Museum of the Moving Image</a> in Long Island City has installed a slot-loading optical drive on one side of its walls where you can insert a blank DVD. A couple of minutes later, it will spit out a free archive - in the form of a virtual disk image - of visual art history for you to immerse yourself in.</p>

<p>I find this project fascinating for two reasons: It stays true to the original medium those works were originally distributed in and I really like the thought that the building&#8217;s walls supposedly have amassed this collection of memories of art exhibited in the museum over its lifetime.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/moving_image_curtain.jpg" alt="Museum of the Moving Image curtain" /></p>

<p><em>&copy; <a href="http://www.flickr.com/photos/57637970@N05/">dwaineashley</a></em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[-- --- •-• ••• •   -•-• --- -•• •]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/morse-code/"/>
    <updated>2012-10-02T23:03:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/morse-code</id>
    <content type="html"><![CDATA[<p>To kick off <em>Real-time</em> we were asked to work on a series of mini projects that involve sensory input and the good old Arduino. When thinking about what invisible data source I&#8217;d like to give a &#8216;voice&#8217;, the first thing that comes to my mind is <em>silence</em>. I like the idea of rewarding people with visuals under the rare moments of complete silence.</p>

<p>After <em>Lee Nutbean</em> introduced us to the <a href="http://www.i-dat.org/eco-os-workshop-ecoid-prototype/">ecoid</a>, a self-sustaining sensor kit that transmits its collected data wirelessly, I fondled with the idea of installing a couple of speakers in the shape of birdhouses around campus.</p>

<p>The speakers would continously play back lists of messages encoded in morse, a series of sounds that only the ones in the know would be able to make sense of. It shouldn&#8217;t be too hard to write an app that would listen to the beeps and decode the messages, or even feed into the system by lighting up the flash on the phone camera in time. Thus creating some kind of local area secret pigeonhole system.</p>

<p>I&#8217;ve been meaning to learn <a href="http://en.wikipedia.org/wiki/Morse_code">Morse Code</a> ever since I fell for Google&#8217;s brilliant <a href="http://www.huffingtonpost.com/2012/04/01/gmail-tap-google-april-fools-day_n_1394635.html">April Fools&#8217; joke</a> of 2012. In my mind there was no doubt that the Morse Code keyboard was a brilliant idea.</p>

<p>Ultimately we came up with another idea in our group that utilises Morse in a different way: We are going to build a twitter client. For birds. And it&#8217;s going to be called <em>birdwire</em>.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/birdwire_logo.png" alt="birdwire logo" /></p>

<p><strong>EDIT 21.10.2012</strong></p>

<p>Today I learned that <em>morse</em> is French for <em>walrus</em>, a piece of information which mandated me to create the following work of nonsense:</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/code_de_morse.jpg" alt="walrus code" /></p>

<p>Actually this tied in beautifully with my recent attempts to re-learn and master <em>blender</em>, the outcomes of which I shall document in another blog post in the near future.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Inspiration: Visualising Sound]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/inspiration-visualising-sound/"/>
    <updated>2012-10-01T23:04:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/inspiration-visualising-sound</id>
    <content type="html"><![CDATA[<p>Feeding into the discussion on the plethora of ways in which we can combine visuals and sound, which happens to tie in nicely with our reading material for the <em>Real-time</em> module (<a href="http://localhost:4000/Sammelsurium/blog/categories/dat301/">DAT301</a>), I would like to share with you two delightful examples of such practice:</p>

<p>First in line is a literal interpretation of the song &#8216;Dynamics of the Subway&#8217; by the Japanese band <a href="http://www.haisuinonasa.com/">haisuinonasa</a> through <a href="http://www.creativeapplications.net/sound/keita-onishi-forest-and-trees-dynamics-of-the-subway/">Keita Onishi</a>. Starting out as a Fischinger-esque translation of beat and notes (kicks, piano chords) into simple geometric shapes, the graphical elements soon transform into an underground car racing through the most colourful world of black and white that I have ever witnessed.</p>

<iframe src="http://player.vimeo.com/video/49367868?title=0&amp;byline=0&amp;portrait=1" width="100%" height="394" frameborder="0" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>


<p>The second piece I discovered when querying the university library database for the works of my favourite visual artist <a href="http://www.ryojiikeda.com/">Ryoji Ikeda</a>. His research project <a href="http://www.ryojiikeda.com/project/other/">cyclo. id vol.1</a> represents the other end of the spectrum, where stereo sound is interpreted in real-time through an oscilloscope and remapped onto different coordinates. Said tome is just an immense collection of such computationally-generated representations and thus not really interesting per se, yet the accompanying disc holds some rather fascinating animated examples.</p>

<p><img src="https://dl.dropbox.com/u/998319/DAT/cyclo.gif" alt="cyclo." /></p>

<p>I&#8217;ve been obsessed with Japanese design and visual culture as of late (if you couldn&#8217;t already tell), so the domination of Japanese artists potrayed in this post may not be entirely coincidental. In an attempt to learn at least the basic 48 kana I started playing <a href="http://www.hiraganapixelparty.com/HiraganaPixelParty.html">Hiragana Pixel Party</a>, a rhythm-based language acquisition game for iOS and Windows Phone. And take note, the university is offering a four-week beginner-level course in Japanese over the summer. Why am I telling you this? I could do with a learning partner in order to make it more fun, that&#8217;s all ^^</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction to Everyware]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/introduction-to-everyware/"/>
    <updated>2012-09-28T18:54:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/introduction-to-everyware</id>
    <content type="html"><![CDATA[<p>Quick feelings update: Out of the three module introduction sessions, Gianni&#8217;s <strong>Everyware</strong> pitch had been the first one to address my educational desires. It pays out to go with your gut every now and again it seems.</p>

<p>Whilst out-in-the-open work with strangers has thus far only enabled me to produce less than mediocre work (I&#8217;m watching you Nutbean!), I am looking forward to the interfacultary collaboration nevertheless. After all, the subject of architecture is very dear to my heart and having a module that essentially requires you to pick up cyberpunk novels for research is more than welcome :></p>

<p><strong>EDIT 1.10.2012</strong></p>

<p>One author that I think Gianni has mentioned during the intro session - Howard Rheingold - just released a book with TED titled <a href="http://boingboing.net/2012/09/30/howard-rheingolds-mind-a.html">Mind Amplifier</a> and it&#8217;s only three quid for the ebook version.</p>

<p><img src="http://craphound.com/images/mind-amplifier-cover.jpg" alt="Mind Amplifiers cover" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hallo Wereld]]></title>
    <link href="http://bloomingbridges.github.com/Sammelsurium/test/"/>
    <updated>2012-09-28T18:28:00+01:00</updated>
    <id>http://bloomingbridges.github.com/Sammelsurium/test</id>
    <content type="html"><![CDATA[<pre><code>&gt; So here we go again
&gt; Final stage of "Digital Art &amp; Technology"
&gt; "Interaction Design" pathway
&gt; I am Florian Brueckner 
&gt; Welcome to my sammelsurium
&gt; 
</code></pre>
]]></content>
  </entry>
  
</feed>
